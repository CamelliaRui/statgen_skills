# TWAS Simulator Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Implement a native Python TWAS simulator for methods development, power analysis, and teaching.

**Architecture:** Native port from mancusolab/twas_sim with modular design: genotype loading, expression models (Elastic Net, LASSO, GBLUP, true effects, external), expression simulation, TWAS association testing, and power analysis modes.

**Tech Stack:** Python 3.10+, scikit-learn (ElasticNet, LASSO), pandas-plink (PLINK file reading), numpy, scipy, matplotlib, seaborn

---

## Task 1: Genotype Manager

**Files:**
- Create: `scripts/twas/__init__.py`
- Create: `scripts/twas/genotype.py`
- Create: `tests/twas/__init__.py`
- Create: `tests/twas/test_genotype.py`

**Step 1: Create directory structure**

```bash
mkdir -p scripts/twas/models tests/twas
touch scripts/twas/__init__.py scripts/twas/models/__init__.py tests/twas/__init__.py
```

**Step 2: Write failing tests for genotype loading**

Create `tests/twas/test_genotype.py`:

```python
# tests/twas/test_genotype.py
"""Tests for genotype loading and management."""

import pytest
import numpy as np
import tempfile
from pathlib import Path


def test_load_plink_returns_genotype_data():
    """Test loading genotypes from PLINK files."""
    from scripts.twas.genotype import load_plink
    
    # Will fail until implemented
    with pytest.raises(FileNotFoundError):
        load_plink("nonexistent_prefix")


def test_get_reference_dir_returns_path():
    """Test reference directory path."""
    from scripts.twas.genotype import get_reference_dir
    
    ref_dir = get_reference_dir()
    assert ref_dir == Path.home() / ".statgen_skills" / "twas_references"


def test_subset_to_cis_region():
    """Test subsetting genotypes to cis-region around a gene."""
    from scripts.twas.genotype import subset_to_cis_region
    
    # Mock genotype data
    n_samples = 100
    n_snps = 50
    genotypes = np.random.randint(0, 3, (n_samples, n_snps))
    positions = np.arange(1000000, 1000000 + n_snps * 1000, 1000)
    
    # Gene at position 1025000, cis window 500kb
    gene_pos = 1025000
    window = 500000
    
    subset, mask = subset_to_cis_region(
        genotypes, positions, gene_pos, window
    )
    
    assert subset.shape[0] == n_samples
    assert subset.shape[1] <= n_snps
    assert np.all(np.abs(positions[mask] - gene_pos) <= window)


def test_sample_individuals():
    """Test random sampling of individuals."""
    from scripts.twas.genotype import sample_individuals
    
    n_total = 1000
    n_sample = 100
    
    indices = sample_individuals(n_total, n_sample, seed=42)
    
    assert len(indices) == n_sample
    assert len(set(indices)) == n_sample  # All unique
    assert all(0 <= i < n_total for i in indices)
    
    # Same seed gives same result
    indices2 = sample_individuals(n_total, n_sample, seed=42)
    assert np.array_equal(indices, indices2)
```

**Step 3: Run tests to verify they fail**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_genotype.py -v
```

Expected: FAIL with import errors

**Step 4: Implement genotype.py**

Create `scripts/twas/genotype.py`:

```python
# scripts/twas/genotype.py
"""
Genotype loading and management for TWAS simulation.

Handles:
- PLINK file loading via pandas-plink
- Cis-region subsetting
- Sample splitting for train/test
- Optional 1000G reference download
"""

from pathlib import Path
from typing import NamedTuple

import numpy as np

try:
    from pandas_plink import read_plink1_bin
    HAS_PANDAS_PLINK = True
except ImportError:
    HAS_PANDAS_PLINK = False


class GenotypeData(NamedTuple):
    """Container for genotype data."""
    genotypes: np.ndarray  # (n_samples, n_snps)
    snp_ids: np.ndarray    # SNP identifiers
    positions: np.ndarray  # Base pair positions
    chromosomes: np.ndarray  # Chromosome numbers
    sample_ids: np.ndarray   # Sample identifiers
    a1: np.ndarray  # Effect allele
    a2: np.ndarray  # Other allele


def get_reference_dir() -> Path:
    """Return directory for TWAS reference files."""
    return Path.home() / ".statgen_skills" / "twas_references"


def load_plink(prefix: str | Path) -> GenotypeData:
    """
    Load genotype data from PLINK binary files.
    
    Args:
        prefix: Path prefix for .bed/.bim/.fam files
        
    Returns:
        GenotypeData with genotypes and variant info
        
    Raises:
        ImportError: If pandas-plink not installed
        FileNotFoundError: If PLINK files not found
    """
    if not HAS_PANDAS_PLINK:
        raise ImportError(
            "pandas-plink required for PLINK file loading. "
            "Install with: pip install pandas-plink"
        )
    
    prefix = Path(prefix)
    bed_file = prefix.with_suffix(".bed")
    if not bed_file.exists():
        # Try adding .bed if prefix already has it
        if not prefix.exists():
            raise FileNotFoundError(f"PLINK files not found: {prefix}")
    
    # Read PLINK files
    (bim, fam, bed) = read_plink1_bin(str(prefix))
    
    # Convert to numpy, handling missing values
    genotypes = bed.compute().values
    genotypes = np.nan_to_num(genotypes, nan=0).astype(np.int8)
    
    return GenotypeData(
        genotypes=genotypes,
        snp_ids=bim["snp"].values,
        positions=bim["pos"].values.astype(np.int64),
        chromosomes=bim["chrom"].values,
        sample_ids=fam["iid"].values,
        a1=bim["a0"].values,  # pandas-plink uses a0/a1
        a2=bim["a1"].values,
    )


def subset_to_cis_region(
    genotypes: np.ndarray,
    positions: np.ndarray,
    gene_position: int,
    window: int = 500000,
) -> tuple[np.ndarray, np.ndarray]:
    """
    Subset genotypes to SNPs within a cis-window of a gene.
    
    Args:
        genotypes: (n_samples, n_snps) genotype matrix
        positions: Array of SNP positions
        gene_position: Gene TSS position
        window: Cis-window size in bp (default 500kb)
        
    Returns:
        Tuple of (subset_genotypes, mask)
    """
    mask = np.abs(positions - gene_position) <= window
    return genotypes[:, mask], mask


def sample_individuals(
    n_total: int,
    n_sample: int,
    seed: int | None = None,
) -> np.ndarray:
    """
    Randomly sample individual indices.
    
    Args:
        n_total: Total number of individuals
        n_sample: Number to sample
        seed: Random seed for reproducibility
        
    Returns:
        Array of sampled indices
    """
    rng = np.random.default_rng(seed)
    return rng.choice(n_total, size=n_sample, replace=False)


def split_samples(
    n_total: int,
    n_eqtl: int,
    n_gwas: int,
    seed: int | None = None,
) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Split samples into eQTL training, GWAS, and test sets.
    
    Args:
        n_total: Total number of samples
        n_eqtl: eQTL training set size
        n_gwas: GWAS set size
        seed: Random seed
        
    Returns:
        Tuple of (eqtl_indices, gwas_indices, test_indices)
    """
    if n_eqtl + n_gwas > n_total:
        raise ValueError(
            f"Requested {n_eqtl} + {n_gwas} = {n_eqtl + n_gwas} samples, "
            f"but only {n_total} available"
        )
    
    rng = np.random.default_rng(seed)
    all_indices = rng.permutation(n_total)
    
    eqtl_idx = all_indices[:n_eqtl]
    gwas_idx = all_indices[n_eqtl:n_eqtl + n_gwas]
    test_idx = all_indices[n_eqtl + n_gwas:]
    
    return eqtl_idx, gwas_idx, test_idx
```

**Step 5: Run tests to verify they pass**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_genotype.py -v
```

Expected: PASS (3 tests)

**Step 6: Commit**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && git add scripts/twas/ tests/twas/ && git commit -m "feat(twas): add genotype loading module

- PLINK file loading via pandas-plink
- Cis-region subsetting for gene-level analysis
- Sample splitting for eQTL/GWAS/test sets

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Task 2: Expression Model Base Class and Registry

**Files:**
- Create: `scripts/twas/models/base.py`
- Create: `scripts/twas/models/__init__.py`
- Create: `tests/twas/test_models.py`

**Step 1: Write failing tests**

Create `tests/twas/test_models.py`:

```python
# tests/twas/test_models.py
"""Tests for expression prediction models."""

import pytest
import numpy as np


def test_model_registry_returns_available_models():
    """Test model registry lists available models."""
    from scripts.twas.models import get_available_models
    
    models = get_available_models()
    assert "elastic_net" in models
    assert "lasso" in models
    assert "gblup" in models
    assert "true_effects" in models


def test_get_model_returns_instance():
    """Test getting model by name."""
    from scripts.twas.models import get_model
    from scripts.twas.models.base import ExpressionModel
    
    model = get_model("elastic_net")
    assert isinstance(model, ExpressionModel)


def test_get_model_raises_for_unknown():
    """Test error for unknown model name."""
    from scripts.twas.models import get_model
    
    with pytest.raises(ValueError, match="Unknown model"):
        get_model("nonexistent_model")


def test_base_model_interface():
    """Test that base model defines required interface."""
    from scripts.twas.models.base import ExpressionModel
    import inspect
    
    # Check required methods exist
    assert hasattr(ExpressionModel, "fit")
    assert hasattr(ExpressionModel, "predict")
    assert hasattr(ExpressionModel, "get_weights")
    assert hasattr(ExpressionModel, "get_nonzero_snps")
    assert hasattr(ExpressionModel, "cross_validate")
```

**Step 2: Run tests to verify they fail**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_models.py -v
```

Expected: FAIL with import errors

**Step 3: Implement base.py**

Create `scripts/twas/models/base.py`:

```python
# scripts/twas/models/base.py
"""
Base class for expression prediction models.

All models must implement this interface for consistent usage
in TWAS simulations.
"""

from abc import ABC, abstractmethod
from typing import Any

import numpy as np
from sklearn.model_selection import cross_val_predict, KFold


class ExpressionModel(ABC):
    """
    Abstract base class for expression prediction models.
    
    All models predict gene expression from genotypes and provide
    weights for TWAS association testing.
    """
    
    def __init__(self, **kwargs: Any):
        """Initialize model with optional parameters."""
        self.weights_: np.ndarray | None = None
        self.is_fitted_: bool = False
    
    @abstractmethod
    def fit(self, X: np.ndarray, y: np.ndarray) -> "ExpressionModel":
        """
        Fit the model to training data.
        
        Args:
            X: Genotype matrix (n_samples, n_snps)
            y: Expression values (n_samples,)
            
        Returns:
            self
        """
        pass
    
    @abstractmethod
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Predict expression from genotypes.
        
        Args:
            X: Genotype matrix (n_samples, n_snps)
            
        Returns:
            Predicted expression values
        """
        pass
    
    def get_weights(self) -> np.ndarray:
        """
        Get model weights for each SNP.
        
        Returns:
            Array of weights (n_snps,)
            
        Raises:
            ValueError: If model not fitted
        """
        if self.weights_ is None:
            raise ValueError("Model not fitted. Call fit() first.")
        return self.weights_
    
    def get_nonzero_snps(self) -> np.ndarray:
        """
        Get indices of SNPs with non-zero weights.
        
        Returns:
            Array of indices
        """
        weights = self.get_weights()
        return np.where(np.abs(weights) > 1e-10)[0]
    
    def cross_validate(
        self,
        X: np.ndarray,
        y: np.ndarray,
        cv: int = 5,
        seed: int | None = None,
    ) -> dict[str, float]:
        """
        Evaluate model with cross-validation.
        
        Args:
            X: Genotype matrix
            y: Expression values
            cv: Number of folds
            seed: Random seed
            
        Returns:
            Dict with cv_r2, cv_corr, n_nonzero
        """
        kfold = KFold(n_splits=cv, shuffle=True, random_state=seed)
        
        # Get cross-validated predictions
        y_pred = np.zeros_like(y)
        for train_idx, test_idx in kfold.split(X):
            # Clone and fit on fold
            model = self.__class__(**self._get_params())
            model.fit(X[train_idx], y[train_idx])
            y_pred[test_idx] = model.predict(X[test_idx])
        
        # Compute metrics
        ss_res = np.sum((y - y_pred) ** 2)
        ss_tot = np.sum((y - y.mean()) ** 2)
        r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0.0
        
        corr = np.corrcoef(y, y_pred)[0, 1] if np.std(y_pred) > 0 else 0.0
        
        # Fit on full data for n_nonzero
        self.fit(X, y)
        n_nonzero = len(self.get_nonzero_snps())
        
        return {
            "cv_r2": max(0, r2),  # Clip negative R2
            "cv_corr": corr if not np.isnan(corr) else 0.0,
            "n_nonzero": n_nonzero,
        }
    
    def _get_params(self) -> dict[str, Any]:
        """Get model parameters for cloning. Override in subclasses."""
        return {}
```

**Step 4: Implement models/__init__.py with registry**

Update `scripts/twas/models/__init__.py`:

```python
# scripts/twas/models/__init__.py
"""
Expression prediction models for TWAS simulation.

Available models:
- elastic_net: ElasticNet regression (L1 + L2)
- lasso: LASSO regression (L1 only)
- gblup: Genomic BLUP (ridge-like)
- true_effects: Oracle model with true causal weights
- external: Load pre-trained weights
"""

from typing import Type

from .base import ExpressionModel

# Model registry - populated as models are implemented
_MODEL_REGISTRY: dict[str, Type[ExpressionModel]] = {}


def register_model(name: str):
    """Decorator to register a model class."""
    def decorator(cls: Type[ExpressionModel]):
        _MODEL_REGISTRY[name] = cls
        return cls
    return decorator


def get_available_models() -> list[str]:
    """Return list of available model names."""
    # Return all planned models even if not yet implemented
    return ["elastic_net", "lasso", "gblup", "true_effects", "external"]


def get_model(name: str, **kwargs) -> ExpressionModel:
    """
    Get a model instance by name.
    
    Args:
        name: Model name (elastic_net, lasso, gblup, true_effects, external)
        **kwargs: Model-specific parameters
        
    Returns:
        Model instance
        
    Raises:
        ValueError: If model name not recognized
    """
    if name not in _MODEL_REGISTRY:
        available = list(_MODEL_REGISTRY.keys())
        if not available:
            raise ValueError(
                f"Unknown model: {name}. No models registered yet."
            )
        raise ValueError(
            f"Unknown model: {name}. Available: {available}"
        )
    return _MODEL_REGISTRY[name](**kwargs)


__all__ = [
    "ExpressionModel",
    "get_available_models",
    "get_model",
    "register_model",
]
```

**Step 5: Run tests to verify partial pass**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_models.py -v
```

Expected: 2 PASS, 2 FAIL (model instantiation will fail until models implemented)

**Step 6: Commit**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && git add scripts/twas/models/ tests/twas/test_models.py && git commit -m "feat(twas): add expression model base class and registry

- Abstract ExpressionModel with fit/predict/get_weights interface
- Cross-validation method with RÂ² and correlation metrics
- Model registry with get_model() factory function

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Task 3: Implement Elastic Net and LASSO Models

**Files:**
- Create: `scripts/twas/models/elastic_net.py`
- Create: `scripts/twas/models/lasso.py`
- Modify: `tests/twas/test_models.py`

**Step 1: Add tests for Elastic Net and LASSO**

Append to `tests/twas/test_models.py`:

```python
# Add to tests/twas/test_models.py

def test_elastic_net_fit_and_predict():
    """Test ElasticNet model fitting and prediction."""
    from scripts.twas.models import get_model
    
    np.random.seed(42)
    n_samples, n_snps = 100, 50
    X = np.random.randint(0, 3, (n_samples, n_snps)).astype(float)
    
    # True sparse effects
    true_weights = np.zeros(n_snps)
    true_weights[:5] = np.random.randn(5) * 0.5
    y = X @ true_weights + np.random.randn(n_samples) * 0.1
    
    model = get_model("elastic_net")
    model.fit(X, y)
    
    # Check predictions
    y_pred = model.predict(X)
    assert y_pred.shape == y.shape
    
    # Check weights are sparse
    weights = model.get_weights()
    assert weights.shape == (n_snps,)
    assert len(model.get_nonzero_snps()) < n_snps  # Should be sparse


def test_lasso_fit_and_predict():
    """Test LASSO model fitting and prediction."""
    from scripts.twas.models import get_model
    
    np.random.seed(42)
    n_samples, n_snps = 100, 50
    X = np.random.randint(0, 3, (n_samples, n_snps)).astype(float)
    true_weights = np.zeros(n_snps)
    true_weights[:3] = [0.5, -0.3, 0.2]
    y = X @ true_weights + np.random.randn(n_samples) * 0.1
    
    model = get_model("lasso")
    model.fit(X, y)
    
    y_pred = model.predict(X)
    assert y_pred.shape == y.shape
    
    # LASSO should be very sparse
    n_nonzero = len(model.get_nonzero_snps())
    assert n_nonzero < n_snps


def test_cross_validate_returns_metrics():
    """Test cross-validation returns proper metrics."""
    from scripts.twas.models import get_model
    
    np.random.seed(42)
    n_samples, n_snps = 200, 30
    X = np.random.randint(0, 3, (n_samples, n_snps)).astype(float)
    true_weights = np.zeros(n_snps)
    true_weights[:5] = np.random.randn(5)
    y = X @ true_weights + np.random.randn(n_samples) * 0.5
    
    model = get_model("elastic_net")
    metrics = model.cross_validate(X, y, cv=5, seed=42)
    
    assert "cv_r2" in metrics
    assert "cv_corr" in metrics
    assert "n_nonzero" in metrics
    assert 0 <= metrics["cv_r2"] <= 1
    assert -1 <= metrics["cv_corr"] <= 1
```

**Step 2: Run tests to verify they fail**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_models.py::test_elastic_net_fit_and_predict -v
```

Expected: FAIL (model not registered)

**Step 3: Implement elastic_net.py**

Create `scripts/twas/models/elastic_net.py`:

```python
# scripts/twas/models/elastic_net.py
"""
Elastic Net expression prediction model.

Combines L1 (LASSO) and L2 (Ridge) regularization for
sparse yet stable coefficient estimates.
"""

from typing import Any

import numpy as np
from sklearn.linear_model import ElasticNetCV

from .base import ExpressionModel
from . import register_model


@register_model("elastic_net")
class ElasticNetModel(ExpressionModel):
    """
    Elastic Net regression for expression prediction.
    
    Uses cross-validation to select optimal regularization parameters.
    Good default choice for TWAS as it produces sparse models while
    handling correlated predictors (SNPs in LD).
    """
    
    def __init__(
        self,
        l1_ratio: float = 0.5,
        n_alphas: int = 100,
        cv: int = 5,
        max_iter: int = 10000,
        random_state: int | None = None,
        **kwargs: Any,
    ):
        """
        Initialize ElasticNet model.
        
        Args:
            l1_ratio: Balance between L1 and L2 (0=Ridge, 1=LASSO)
            n_alphas: Number of alpha values to try
            cv: Cross-validation folds for alpha selection
            max_iter: Maximum iterations for optimization
            random_state: Random seed
        """
        super().__init__(**kwargs)
        self.l1_ratio = l1_ratio
        self.n_alphas = n_alphas
        self.cv = cv
        self.max_iter = max_iter
        self.random_state = random_state
        self._model: ElasticNetCV | None = None
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> "ElasticNetModel":
        """Fit ElasticNet with cross-validated alpha selection."""
        self._model = ElasticNetCV(
            l1_ratio=self.l1_ratio,
            n_alphas=self.n_alphas,
            cv=self.cv,
            max_iter=self.max_iter,
            random_state=self.random_state,
        )
        self._model.fit(X, y)
        self.weights_ = self._model.coef_
        self.is_fitted_ = True
        return self
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Predict expression values."""
        if self._model is None:
            raise ValueError("Model not fitted. Call fit() first.")
        return self._model.predict(X)
    
    def _get_params(self) -> dict[str, Any]:
        """Get parameters for cloning."""
        return {
            "l1_ratio": self.l1_ratio,
            "n_alphas": self.n_alphas,
            "cv": self.cv,
            "max_iter": self.max_iter,
            "random_state": self.random_state,
        }
```

**Step 4: Implement lasso.py**

Create `scripts/twas/models/lasso.py`:

```python
# scripts/twas/models/lasso.py
"""
LASSO expression prediction model.

L1 regularization produces very sparse models, selecting
only the strongest eQTL signals.
"""

from typing import Any

import numpy as np
from sklearn.linear_model import LassoCV

from .base import ExpressionModel
from . import register_model


@register_model("lasso")
class LassoModel(ExpressionModel):
    """
    LASSO regression for expression prediction.
    
    Uses pure L1 regularization for maximum sparsity.
    Best when expecting few true causal cis-eQTLs.
    """
    
    def __init__(
        self,
        n_alphas: int = 100,
        cv: int = 5,
        max_iter: int = 10000,
        random_state: int | None = None,
        **kwargs: Any,
    ):
        """
        Initialize LASSO model.
        
        Args:
            n_alphas: Number of alpha values to try
            cv: Cross-validation folds
            max_iter: Maximum iterations
            random_state: Random seed
        """
        super().__init__(**kwargs)
        self.n_alphas = n_alphas
        self.cv = cv
        self.max_iter = max_iter
        self.random_state = random_state
        self._model: LassoCV | None = None
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> "LassoModel":
        """Fit LASSO with cross-validated alpha selection."""
        self._model = LassoCV(
            n_alphas=self.n_alphas,
            cv=self.cv,
            max_iter=self.max_iter,
            random_state=self.random_state,
        )
        self._model.fit(X, y)
        self.weights_ = self._model.coef_
        self.is_fitted_ = True
        return self
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Predict expression values."""
        if self._model is None:
            raise ValueError("Model not fitted. Call fit() first.")
        return self._model.predict(X)
    
    def _get_params(self) -> dict[str, Any]:
        """Get parameters for cloning."""
        return {
            "n_alphas": self.n_alphas,
            "cv": self.cv,
            "max_iter": self.max_iter,
            "random_state": self.random_state,
        }
```

**Step 5: Update models/__init__.py to import models**

Update `scripts/twas/models/__init__.py` to add imports at the end:

```python
# Add at end of scripts/twas/models/__init__.py

# Import models to trigger registration
from . import elastic_net
from . import lasso
```

**Step 6: Run tests to verify they pass**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_models.py -v
```

Expected: 7 tests PASS (registry test for get_model may still fail for gblup/true_effects)

**Step 7: Commit**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && git add scripts/twas/models/ tests/twas/test_models.py && git commit -m "feat(twas): add ElasticNet and LASSO models

- ElasticNetCV with L1/L2 regularization
- LassoCV for maximum sparsity
- Cross-validated alpha selection
- Auto-registered via decorator

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Task 4: Implement GBLUP and True Effects Models

**Files:**
- Create: `scripts/twas/models/gblup.py`
- Create: `scripts/twas/models/true_effects.py`
- Modify: `tests/twas/test_models.py`

**Step 1: Add tests for GBLUP and True Effects**

Append to `tests/twas/test_models.py`:

```python
# Add to tests/twas/test_models.py

def test_gblup_fit_and_predict():
    """Test GBLUP model fitting and prediction."""
    from scripts.twas.models import get_model
    
    np.random.seed(42)
    n_samples, n_snps = 100, 50
    X = np.random.randint(0, 3, (n_samples, n_snps)).astype(float)
    
    # Dense effects (GBLUP assumes many small effects)
    true_weights = np.random.randn(n_snps) * 0.1
    y = X @ true_weights + np.random.randn(n_samples) * 0.1
    
    model = get_model("gblup")
    model.fit(X, y)
    
    y_pred = model.predict(X)
    assert y_pred.shape == y.shape
    
    # GBLUP uses all SNPs (not sparse)
    weights = model.get_weights()
    assert weights.shape == (n_snps,)
    # Most weights should be non-zero
    assert len(model.get_nonzero_snps()) > n_snps * 0.5


def test_true_effects_perfect_prediction():
    """Test true effects model with known weights."""
    from scripts.twas.models import get_model
    
    np.random.seed(42)
    n_samples, n_snps = 100, 50
    X = np.random.randint(0, 3, (n_samples, n_snps)).astype(float)
    
    # Known true weights
    true_weights = np.zeros(n_snps)
    true_weights[:5] = [1.0, -0.5, 0.3, -0.2, 0.1]
    y_true = X @ true_weights
    
    # Initialize with true weights
    model = get_model("true_effects", true_weights=true_weights)
    model.fit(X, y_true)  # fit is a no-op for true effects
    
    y_pred = model.predict(X)
    
    # Should be perfect prediction
    np.testing.assert_allclose(y_pred, y_true, rtol=1e-10)
    
    # Weights should match
    np.testing.assert_allclose(model.get_weights(), true_weights)
```

**Step 2: Run tests to verify they fail**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_models.py::test_gblup_fit_and_predict -v
```

Expected: FAIL (model not registered)

**Step 3: Implement gblup.py**

Create `scripts/twas/models/gblup.py`:

```python
# scripts/twas/models/gblup.py
"""
Genomic BLUP (Best Linear Unbiased Prediction) model.

Ridge-like regression that uses all SNPs with shrinkage.
Appropriate when many SNPs have small effects (polygenic architecture).
"""

from typing import Any

import numpy as np
from sklearn.linear_model import RidgeCV

from .base import ExpressionModel
from . import register_model


@register_model("gblup")
class GBLUPModel(ExpressionModel):
    """
    GBLUP-style model using Ridge regression.
    
    Shrinks all coefficients towards zero but keeps them non-zero.
    Best for highly polygenic expression (many cis-eQTLs with small effects).
    """
    
    def __init__(
        self,
        alphas: tuple[float, ...] = (0.1, 1.0, 10.0, 100.0, 1000.0),
        cv: int = 5,
        **kwargs: Any,
    ):
        """
        Initialize GBLUP model.
        
        Args:
            alphas: Regularization strengths to try
            cv: Cross-validation folds
        """
        super().__init__(**kwargs)
        self.alphas = alphas
        self.cv = cv
        self._model: RidgeCV | None = None
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> "GBLUPModel":
        """Fit Ridge regression with cross-validated alpha."""
        self._model = RidgeCV(
            alphas=self.alphas,
            cv=self.cv,
        )
        self._model.fit(X, y)
        self.weights_ = self._model.coef_
        self.is_fitted_ = True
        return self
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Predict expression values."""
        if self._model is None:
            raise ValueError("Model not fitted. Call fit() first.")
        return self._model.predict(X)
    
    def _get_params(self) -> dict[str, Any]:
        """Get parameters for cloning."""
        return {
            "alphas": self.alphas,
            "cv": self.cv,
        }
```

**Step 4: Implement true_effects.py**

Create `scripts/twas/models/true_effects.py`:

```python
# scripts/twas/models/true_effects.py
"""
True effects oracle model.

Uses the actual causal weights for prediction.
Provides upper bound on TWAS power - what we'd achieve
with perfect expression prediction.
"""

from typing import Any

import numpy as np

from .base import ExpressionModel
from . import register_model


@register_model("true_effects")
class TrueEffectsModel(ExpressionModel):
    """
    Oracle model using true causal weights.
    
    This model doesn't learn from data - it uses pre-specified
    true causal effect sizes. Useful for:
    - Upper bound on achievable TWAS power
    - Isolating the impact of prediction error
    - Validation and debugging
    """
    
    def __init__(
        self,
        true_weights: np.ndarray | None = None,
        **kwargs: Any,
    ):
        """
        Initialize with true causal weights.
        
        Args:
            true_weights: Array of true effect sizes (n_snps,)
        """
        super().__init__(**kwargs)
        self._true_weights = true_weights
        if true_weights is not None:
            self.weights_ = np.array(true_weights)
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> "TrueEffectsModel":
        """
        Fit is a no-op - weights are pre-specified.
        
        Validates that weights match X dimensions.
        """
        if self._true_weights is None:
            raise ValueError(
                "TrueEffectsModel requires true_weights to be set. "
                "Pass true_weights=... during initialization."
            )
        
        if len(self._true_weights) != X.shape[1]:
            raise ValueError(
                f"true_weights length ({len(self._true_weights)}) "
                f"doesn't match n_snps ({X.shape[1]})"
            )
        
        self.weights_ = np.array(self._true_weights)
        self.is_fitted_ = True
        return self
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Predict using true weights."""
        if self.weights_ is None:
            raise ValueError("Model not fitted. Call fit() first.")
        return X @ self.weights_
    
    def _get_params(self) -> dict[str, Any]:
        """Get parameters for cloning."""
        return {"true_weights": self._true_weights}
```

**Step 5: Update models/__init__.py imports**

Update `scripts/twas/models/__init__.py` to add:

```python
# Add to imports at end of scripts/twas/models/__init__.py
from . import gblup
from . import true_effects
```

**Step 6: Run tests to verify they pass**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_models.py -v
```

Expected: All tests PASS

**Step 7: Commit**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && git add scripts/twas/models/ tests/twas/test_models.py && git commit -m "feat(twas): add GBLUP and TrueEffects models

- GBLUP: Ridge regression for polygenic expression
- TrueEffects: Oracle model for power upper bounds
- Complete model suite for TWAS simulation

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Task 5: Expression Simulation Module

**Files:**
- Create: `scripts/twas/expression.py`
- Create: `tests/twas/test_expression.py`

**Step 1: Write failing tests**

Create `tests/twas/test_expression.py`:

```python
# tests/twas/test_expression.py
"""Tests for expression simulation."""

import pytest
import numpy as np


def test_simulate_causal_effects():
    """Test generating causal eQTL effects."""
    from scripts.twas.expression import simulate_causal_effects
    
    n_snps = 100
    n_causal = 5
    h2_cis = 0.1
    
    effects, causal_idx = simulate_causal_effects(
        n_snps=n_snps,
        n_causal=n_causal,
        h2_cis=h2_cis,
        seed=42,
    )
    
    assert effects.shape == (n_snps,)
    assert len(causal_idx) == n_causal
    assert np.sum(effects != 0) == n_causal


def test_simulate_expression():
    """Test simulating expression from genotypes."""
    from scripts.twas.expression import simulate_expression
    
    np.random.seed(42)
    n_samples = 500
    n_snps = 100
    h2_cis = 0.1
    
    genotypes = np.random.randint(0, 3, (n_samples, n_snps)).astype(float)
    # Standardize genotypes
    genotypes = (genotypes - genotypes.mean(0)) / (genotypes.std(0) + 1e-8)
    
    expression, effects, causal_idx = simulate_expression(
        genotypes=genotypes,
        h2_cis=h2_cis,
        n_causal=5,
        seed=42,
    )
    
    assert expression.shape == (n_samples,)
    assert effects.shape == (n_snps,)
    
    # Check variance is approximately as expected
    genetic_var = np.var(genotypes @ effects)
    total_var = np.var(expression)
    observed_h2 = genetic_var / total_var
    # Allow some variance due to finite sample
    assert 0.01 < observed_h2 < 0.5


def test_simulate_multi_gene_expression():
    """Test simulating expression for multiple genes."""
    from scripts.twas.expression import simulate_multi_gene_expression
    
    np.random.seed(42)
    n_samples = 200
    n_genes = 10
    n_snps_per_gene = 50
    
    # Mock genotype data per gene
    genotypes_list = [
        np.random.randn(n_samples, n_snps_per_gene)
        for _ in range(n_genes)
    ]
    
    result = simulate_multi_gene_expression(
        genotypes_list=genotypes_list,
        h2_cis=0.1,
        n_causal=3,
        seed=42,
    )
    
    assert "expression" in result
    assert "effects" in result
    assert "causal_indices" in result
    assert result["expression"].shape == (n_samples, n_genes)
    assert len(result["effects"]) == n_genes
```

**Step 2: Run tests to verify they fail**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_expression.py -v
```

Expected: FAIL with import errors

**Step 3: Implement expression.py**

Create `scripts/twas/expression.py`:

```python
# scripts/twas/expression.py
"""
Expression simulation for TWAS.

Generates gene expression phenotypes from genotypes with
configurable genetic architecture (number of causal variants,
cis-heritability).
"""

from typing import TypedDict

import numpy as np


class MultiGeneResult(TypedDict):
    """Result container for multi-gene expression simulation."""
    expression: np.ndarray      # (n_samples, n_genes)
    effects: list[np.ndarray]   # List of effect arrays per gene
    causal_indices: list[np.ndarray]  # Causal SNP indices per gene


def simulate_causal_effects(
    n_snps: int,
    n_causal: int,
    h2_cis: float,
    seed: int | None = None,
) -> tuple[np.ndarray, np.ndarray]:
    """
    Generate causal eQTL effect sizes.
    
    Effects are scaled so that genetic variance equals h2_cis
    when genotypes are standardized.
    
    Args:
        n_snps: Number of SNPs in cis-region
        n_causal: Number of causal variants
        h2_cis: Target cis-heritability
        seed: Random seed
        
    Returns:
        Tuple of (effects array, indices of causal SNPs)
    """
    rng = np.random.default_rng(seed)
    
    # Sample causal indices
    if n_causal > n_snps:
        raise ValueError(f"n_causal ({n_causal}) > n_snps ({n_snps})")
    
    causal_idx = rng.choice(n_snps, size=n_causal, replace=False)
    
    # Generate raw effects from standard normal
    raw_effects = rng.standard_normal(n_causal)
    
    # Scale effects so sum of squared effects equals h2_cis
    # (assuming standardized genotypes with var=1)
    scale = np.sqrt(h2_cis / np.sum(raw_effects ** 2))
    
    effects = np.zeros(n_snps)
    effects[causal_idx] = raw_effects * scale
    
    return effects, causal_idx


def simulate_expression(
    genotypes: np.ndarray,
    h2_cis: float,
    n_causal: int = 1,
    seed: int | None = None,
) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Simulate gene expression from genotypes.
    
    Expression = genetic component + environmental noise
    where genetic variance / total variance = h2_cis
    
    Args:
        genotypes: (n_samples, n_snps) genotype matrix (should be standardized)
        h2_cis: Cis-heritability
        n_causal: Number of causal cis-eQTLs
        seed: Random seed
        
    Returns:
        Tuple of (expression, effects, causal_indices)
    """
    rng = np.random.default_rng(seed)
    n_samples, n_snps = genotypes.shape
    
    # Generate causal effects
    effects, causal_idx = simulate_causal_effects(
        n_snps=n_snps,
        n_causal=n_causal,
        h2_cis=h2_cis,
        seed=seed,
    )
    
    # Genetic component
    g = genotypes @ effects
    
    # Scale genetic component to have variance = h2_cis
    g_var = np.var(g)
    if g_var > 0:
        g = g * np.sqrt(h2_cis / g_var)
    
    # Environmental noise variance = 1 - h2_cis
    env_var = 1 - h2_cis
    noise = rng.standard_normal(n_samples) * np.sqrt(env_var)
    
    # Total expression
    expression = g + noise
    
    # Standardize to mean=0, var=1
    expression = (expression - expression.mean()) / (expression.std() + 1e-8)
    
    return expression, effects, causal_idx


def simulate_multi_gene_expression(
    genotypes_list: list[np.ndarray],
    h2_cis: float | list[float],
    n_causal: int | list[int] = 1,
    seed: int | None = None,
) -> MultiGeneResult:
    """
    Simulate expression for multiple genes.
    
    Args:
        genotypes_list: List of genotype matrices, one per gene
        h2_cis: Cis-heritability (single value or per-gene list)
        n_causal: Number of causal eQTLs (single value or per-gene list)
        seed: Random seed
        
    Returns:
        MultiGeneResult with expression matrix and effect details
    """
    rng = np.random.default_rng(seed)
    n_genes = len(genotypes_list)
    n_samples = genotypes_list[0].shape[0]
    
    # Convert scalar parameters to lists
    if isinstance(h2_cis, (int, float)):
        h2_cis_list = [h2_cis] * n_genes
    else:
        h2_cis_list = list(h2_cis)
    
    if isinstance(n_causal, int):
        n_causal_list = [n_causal] * n_genes
    else:
        n_causal_list = list(n_causal)
    
    # Generate seeds for each gene
    gene_seeds = rng.integers(0, 2**31, size=n_genes)
    
    expression_matrix = np.zeros((n_samples, n_genes))
    effects_list = []
    causal_indices_list = []
    
    for i in range(n_genes):
        expr, effects, causal_idx = simulate_expression(
            genotypes=genotypes_list[i],
            h2_cis=h2_cis_list[i],
            n_causal=n_causal_list[i],
            seed=int(gene_seeds[i]),
        )
        expression_matrix[:, i] = expr
        effects_list.append(effects)
        causal_indices_list.append(causal_idx)
    
    return MultiGeneResult(
        expression=expression_matrix,
        effects=effects_list,
        causal_indices=causal_indices_list,
    )
```

**Step 4: Run tests to verify they pass**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_expression.py -v
```

Expected: All 3 tests PASS

**Step 5: Commit**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && git add scripts/twas/expression.py tests/twas/test_expression.py && git commit -m "feat(twas): add expression simulation module

- Causal effect generation with configurable sparsity
- Single-gene and multi-gene expression simulation
- Heritability-calibrated genetic/environmental variance

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Task 6: TWAS Association Testing

**Files:**
- Create: `scripts/twas/association.py`
- Create: `tests/twas/test_association.py`

**Step 1: Write failing tests**

Create `tests/twas/test_association.py`:

```python
# tests/twas/test_association.py
"""Tests for TWAS association testing."""

import pytest
import numpy as np


def test_compute_twas_z():
    """Test TWAS Z-score computation."""
    from scripts.twas.association import compute_twas_z
    
    np.random.seed(42)
    n_samples = 1000
    
    # Simulated predicted expression and phenotype
    pred_expression = np.random.randn(n_samples)
    
    # Correlated phenotype (should give significant Z)
    phenotype = 0.5 * pred_expression + np.random.randn(n_samples) * 0.5
    
    z, p = compute_twas_z(pred_expression, phenotype)
    
    assert isinstance(z, float)
    assert isinstance(p, float)
    assert p < 0.05  # Should be significant


def test_run_twas_returns_results():
    """Test running TWAS on multiple genes."""
    from scripts.twas.association import run_twas
    
    np.random.seed(42)
    n_samples = 500
    n_genes = 10
    
    # Simulated predicted expression matrix
    pred_expression = np.random.randn(n_samples, n_genes)
    
    # Phenotype correlated with first 3 genes
    true_effects = np.zeros(n_genes)
    true_effects[:3] = [0.3, 0.2, 0.1]
    phenotype = pred_expression @ true_effects + np.random.randn(n_samples) * 0.5
    
    results = run_twas(pred_expression, phenotype)
    
    assert "z_scores" in results
    assert "p_values" in results
    assert len(results["z_scores"]) == n_genes
    
    # First genes should have lower p-values
    assert results["p_values"][0] < results["p_values"][-1]


def test_compute_power_fdr():
    """Test power and FDR computation."""
    from scripts.twas.association import compute_power_fdr
    
    n_genes = 100
    n_causal = 10
    
    # Mock results
    p_values = np.random.uniform(0, 1, n_genes)
    # Make causal genes significant
    p_values[:n_causal] = np.random.uniform(0, 0.01, n_causal)
    
    causal_mask = np.zeros(n_genes, dtype=bool)
    causal_mask[:n_causal] = True
    
    metrics = compute_power_fdr(p_values, causal_mask, alpha=0.05)
    
    assert "power" in metrics
    assert "fdr" in metrics
    assert "n_discoveries" in metrics
    assert 0 <= metrics["power"] <= 1
    assert 0 <= metrics["fdr"] <= 1
```

**Step 2: Run tests to verify they fail**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_association.py -v
```

Expected: FAIL with import errors

**Step 3: Implement association.py**

Create `scripts/twas/association.py`:

```python
# scripts/twas/association.py
"""
TWAS association testing.

Computes Z-scores for gene-trait associations using
predicted expression values.
"""

from typing import TypedDict

import numpy as np
from scipy import stats


class TWASResults(TypedDict):
    """Container for TWAS results."""
    z_scores: np.ndarray
    p_values: np.ndarray


class PowerFDRMetrics(TypedDict):
    """Power and FDR metrics."""
    power: float
    fdr: float
    n_discoveries: int
    n_true_positives: int
    n_false_positives: int


def compute_twas_z(
    pred_expression: np.ndarray,
    phenotype: np.ndarray,
) -> tuple[float, float]:
    """
    Compute TWAS Z-score for a single gene.
    
    Uses correlation-based test statistic:
    Z = r * sqrt(n-2) / sqrt(1-r^2)
    
    Args:
        pred_expression: Predicted expression (n_samples,)
        phenotype: Trait phenotype (n_samples,)
        
    Returns:
        Tuple of (z_score, p_value)
    """
    n = len(pred_expression)
    
    # Compute correlation
    r = np.corrcoef(pred_expression, phenotype)[0, 1]
    
    if np.isnan(r) or np.abs(r) > 0.9999:
        # Handle degenerate cases
        return 0.0, 1.0
    
    # Convert to Z-score
    z = r * np.sqrt(n - 2) / np.sqrt(1 - r**2)
    
    # Two-sided p-value
    p = 2 * stats.norm.sf(np.abs(z))
    
    return float(z), float(p)


def run_twas(
    pred_expression: np.ndarray,
    phenotype: np.ndarray,
    gene_ids: np.ndarray | None = None,
) -> TWASResults:
    """
    Run TWAS association test for multiple genes.
    
    Args:
        pred_expression: (n_samples, n_genes) predicted expression matrix
        phenotype: (n_samples,) trait phenotype
        gene_ids: Optional gene identifiers
        
    Returns:
        TWASResults with Z-scores and p-values
    """
    n_samples, n_genes = pred_expression.shape
    
    z_scores = np.zeros(n_genes)
    p_values = np.ones(n_genes)
    
    for i in range(n_genes):
        z_scores[i], p_values[i] = compute_twas_z(
            pred_expression[:, i], phenotype
        )
    
    return TWASResults(
        z_scores=z_scores,
        p_values=p_values,
    )


def compute_power_fdr(
    p_values: np.ndarray,
    causal_mask: np.ndarray,
    alpha: float = 0.05,
) -> PowerFDRMetrics:
    """
    Compute power and FDR from TWAS results.
    
    Args:
        p_values: Array of p-values per gene
        causal_mask: Boolean array indicating true causal genes
        alpha: Significance threshold
        
    Returns:
        PowerFDRMetrics with power, FDR, and discovery counts
    """
    # Discoveries at significance threshold
    discoveries = p_values < alpha
    n_discoveries = np.sum(discoveries)
    
    # True positives: causal genes that are discovered
    true_positives = discoveries & causal_mask
    n_true_positives = np.sum(true_positives)
    
    # False positives: non-causal genes that are discovered  
    false_positives = discoveries & ~causal_mask
    n_false_positives = np.sum(false_positives)
    
    # Power: fraction of causal genes discovered
    n_causal = np.sum(causal_mask)
    power = n_true_positives / n_causal if n_causal > 0 else 0.0
    
    # FDR: fraction of discoveries that are false
    fdr = n_false_positives / n_discoveries if n_discoveries > 0 else 0.0
    
    return PowerFDRMetrics(
        power=power,
        fdr=fdr,
        n_discoveries=int(n_discoveries),
        n_true_positives=int(n_true_positives),
        n_false_positives=int(n_false_positives),
    )
```

**Step 4: Run tests to verify they pass**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_association.py -v
```

Expected: All 3 tests PASS

**Step 5: Commit**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && git add scripts/twas/association.py tests/twas/test_association.py && git commit -m "feat(twas): add association testing module

- Correlation-based TWAS Z-score computation
- Multi-gene association testing
- Power and FDR metrics calculation

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Task 7: Main Simulation Orchestrator

**Files:**
- Create: `scripts/twas/simulate.py`
- Update: `scripts/twas/__init__.py`
- Create: `tests/twas/test_simulate.py`

**Step 1: Write failing tests**

Create `tests/twas/test_simulate.py`:

```python
# tests/twas/test_simulate.py
"""Tests for main TWAS simulation."""

import pytest
import numpy as np
import tempfile
from pathlib import Path


@pytest.fixture
def mock_genotypes():
    """Generate mock genotype data for testing."""
    np.random.seed(42)
    n_samples = 500
    n_genes = 20
    n_snps_per_gene = 50
    
    genotypes = []
    for _ in range(n_genes):
        g = np.random.randint(0, 3, (n_samples, n_snps_per_gene)).astype(float)
        # Standardize
        g = (g - g.mean(0)) / (g.std(0) + 1e-8)
        genotypes.append(g)
    
    return genotypes


def test_simulate_twas_basic(mock_genotypes):
    """Test basic TWAS simulation."""
    from scripts.twas.simulate import simulate_twas
    
    with tempfile.TemporaryDirectory() as tmpdir:
        result = simulate_twas(
            genotypes_list=mock_genotypes,
            n_causal_genes=5,
            h2_cis=0.1,
            h2_trait=0.5,
            prop_mediated=0.2,
            models=["elastic_net"],
            output_dir=tmpdir,
            seed=42,
        )
        
        assert "twas_results" in result
        assert "model_performance" in result
        assert "true_effects" in result
        assert "power_metrics" in result
        
        # Check output files created
        assert Path(tmpdir, "simulation_params.json").exists()
        assert Path(tmpdir, "twas_results.csv").exists()


def test_simulate_twas_multiple_models(mock_genotypes):
    """Test simulation with multiple models."""
    from scripts.twas.simulate import simulate_twas
    
    with tempfile.TemporaryDirectory() as tmpdir:
        result = simulate_twas(
            genotypes_list=mock_genotypes,
            n_causal_genes=3,
            h2_cis=0.1,
            h2_trait=0.5,
            prop_mediated=0.1,
            models=["elastic_net", "lasso"],
            output_dir=tmpdir,
            seed=42,
        )
        
        # Should have results for each model
        assert "elastic_net" in result["twas_results"]
        assert "lasso" in result["twas_results"]
        
        # Performance metrics for each model
        assert "elastic_net" in result["model_performance"]
        assert "lasso" in result["model_performance"]


def test_simulate_twas_saves_outputs(mock_genotypes):
    """Test that all expected output files are saved."""
    from scripts.twas.simulate import simulate_twas
    
    with tempfile.TemporaryDirectory() as tmpdir:
        simulate_twas(
            genotypes_list=mock_genotypes,
            n_causal_genes=3,
            h2_cis=0.1,
            h2_trait=0.5,
            prop_mediated=0.1,
            models=["elastic_net"],
            output_dir=tmpdir,
            seed=42,
        )
        
        # Check all expected files
        expected_files = [
            "simulation_params.json",
            "true_effects.csv",
            "twas_results.csv",
            "model_performance.csv",
            "summary.json",
        ]
        
        for fname in expected_files:
            assert Path(tmpdir, fname).exists(), f"Missing: {fname}"
```

**Step 2: Run tests to verify they fail**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_simulate.py -v
```

Expected: FAIL with import errors

**Step 3: Implement simulate.py**

Create `scripts/twas/simulate.py`:

```python
# scripts/twas/simulate.py
"""
Main TWAS simulation orchestrator.

Coordinates:
1. Expression simulation
2. Model training
3. TWAS association testing
4. Result aggregation and output
"""

import json
from pathlib import Path
from typing import Any, TypedDict

import numpy as np
import pandas as pd

from .expression import simulate_multi_gene_expression
from .association import run_twas, compute_power_fdr
from .models import get_model


class SimulationResult(TypedDict):
    """Complete simulation result."""
    twas_results: dict[str, dict]
    model_performance: dict[str, dict]
    true_effects: dict
    power_metrics: dict[str, dict]


def simulate_twas(
    genotypes_list: list[np.ndarray],
    n_causal_genes: int,
    h2_cis: float = 0.1,
    h2_trait: float = 0.5,
    prop_mediated: float = 0.1,
    n_causal_cis: int = 1,
    models: list[str] = ["elastic_net"],
    output_dir: str | Path | None = None,
    seed: int | None = None,
    verbose: bool = True,
) -> SimulationResult:
    """
    Run a complete TWAS simulation.
    
    Args:
        genotypes_list: List of genotype matrices (n_samples, n_snps) per gene
        n_causal_genes: Number of genes with true trait effects
        h2_cis: Cis-heritability of expression
        h2_trait: Total trait heritability
        prop_mediated: Proportion of h2_trait mediated through expression
        n_causal_cis: Number of causal cis-eQTLs per gene
        models: List of model names to use
        output_dir: Directory to save outputs
        seed: Random seed
        verbose: Print progress
        
    Returns:
        SimulationResult with all results
    """
    rng = np.random.default_rng(seed)
    n_genes = len(genotypes_list)
    n_samples = genotypes_list[0].shape[0]
    
    if verbose:
        print(f"Running TWAS simulation: {n_genes} genes, {n_samples} samples")
    
    # Setup output directory
    if output_dir is not None:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. Simulate expression
    if verbose:
        print("Simulating gene expression...")
    
    expr_result = simulate_multi_gene_expression(
        genotypes_list=genotypes_list,
        h2_cis=h2_cis,
        n_causal=n_causal_cis,
        seed=seed,
    )
    expression = expr_result["expression"]
    
    # 2. Select causal genes for trait
    causal_gene_idx = rng.choice(n_genes, size=n_causal_genes, replace=False)
    causal_mask = np.zeros(n_genes, dtype=bool)
    causal_mask[causal_gene_idx] = True
    
    # 3. Simulate trait phenotype
    # Variance mediated through expression
    mediated_var = h2_trait * prop_mediated
    # Direct genetic variance (not through expression)
    direct_var = h2_trait * (1 - prop_mediated)
    # Environmental variance
    env_var = 1 - h2_trait
    
    # Gene effects on trait
    gene_effects = np.zeros(n_genes)
    gene_effects[causal_gene_idx] = rng.standard_normal(n_causal_genes)
    gene_effects = gene_effects / np.sqrt(np.sum(gene_effects**2) + 1e-8)
    gene_effects *= np.sqrt(mediated_var)
    
    # Phenotype components
    mediated_component = expression @ gene_effects
    direct_component = rng.standard_normal(n_samples) * np.sqrt(direct_var)
    env_component = rng.standard_normal(n_samples) * np.sqrt(env_var)
    
    phenotype = mediated_component + direct_component + env_component
    phenotype = (phenotype - phenotype.mean()) / (phenotype.std() + 1e-8)
    
    # 4. Split samples: eQTL training vs GWAS
    n_eqtl = min(n_samples // 2, 500)
    n_gwas = n_samples - n_eqtl
    
    all_idx = rng.permutation(n_samples)
    eqtl_idx = all_idx[:n_eqtl]
    gwas_idx = all_idx[n_eqtl:]
    
    # 5. Train models and predict expression
    if verbose:
        print(f"Training models: {models}")
    
    twas_results = {}
    model_performance = {}
    
    for model_name in models:
        if verbose:
            print(f"  Training {model_name}...")
        
        pred_expression = np.zeros((n_gwas, n_genes))
        cv_metrics = []
        
        for g in range(n_genes):
            # Get genotypes for this gene
            X = genotypes_list[g]
            y = expression[:, g]
            
            # Train on eQTL samples
            X_train, y_train = X[eqtl_idx], y[eqtl_idx]
            X_test = X[gwas_idx]
            
            # Get model (with true weights for oracle model)
            if model_name == "true_effects":
                model = get_model(
                    model_name,
                    true_weights=expr_result["effects"][g]
                )
            else:
                model = get_model(model_name, random_state=seed)
            
            # Cross-validate and fit
            try:
                metrics = model.cross_validate(X_train, y_train, cv=5, seed=seed)
                cv_metrics.append(metrics)
            except Exception:
                # Fallback if CV fails
                model.fit(X_train, y_train)
                cv_metrics.append({"cv_r2": 0, "cv_corr": 0, "n_nonzero": 0})
            
            # Predict on GWAS samples
            pred_expression[:, g] = model.predict(X_test)
        
        # Run TWAS
        results = run_twas(pred_expression, phenotype[gwas_idx])
        
        # Compute power/FDR
        power_fdr = compute_power_fdr(
            results["p_values"], causal_mask, alpha=0.05
        )
        
        twas_results[model_name] = {
            "z_scores": results["z_scores"].tolist(),
            "p_values": results["p_values"].tolist(),
        }
        
        model_performance[model_name] = {
            "mean_cv_r2": np.mean([m["cv_r2"] for m in cv_metrics]),
            "mean_cv_corr": np.mean([m["cv_corr"] for m in cv_metrics]),
            "mean_n_nonzero": np.mean([m["n_nonzero"] for m in cv_metrics]),
        }
        
        twas_results[model_name]["power_metrics"] = dict(power_fdr)
    
    # 6. Compile results
    true_effects_info = {
        "causal_gene_indices": causal_gene_idx.tolist(),
        "gene_trait_effects": gene_effects.tolist(),
        "cis_effects": [e.tolist() for e in expr_result["effects"]],
        "cis_causal_indices": [idx.tolist() for idx in expr_result["causal_indices"]],
    }
    
    result = SimulationResult(
        twas_results=twas_results,
        model_performance=model_performance,
        true_effects=true_effects_info,
        power_metrics={m: twas_results[m]["power_metrics"] for m in models},
    )
    
    # 7. Save outputs
    if output_dir is not None:
        _save_outputs(
            output_dir=output_dir,
            result=result,
            params={
                "n_genes": n_genes,
                "n_samples": n_samples,
                "n_causal_genes": n_causal_genes,
                "h2_cis": h2_cis,
                "h2_trait": h2_trait,
                "prop_mediated": prop_mediated,
                "n_causal_cis": n_causal_cis,
                "models": models,
                "seed": seed,
            },
            verbose=verbose,
        )
    
    if verbose:
        print("Simulation complete!")
        for m in models:
            pm = result["power_metrics"][m]
            print(f"  {m}: power={pm['power']:.3f}, FDR={pm['fdr']:.3f}")
    
    return result


def _save_outputs(
    output_dir: Path,
    result: SimulationResult,
    params: dict[str, Any],
    verbose: bool = True,
) -> None:
    """Save simulation outputs to files."""
    
    # Parameters
    with open(output_dir / "simulation_params.json", "w") as f:
        json.dump(params, f, indent=2)
    
    # True effects
    pd.DataFrame({
        "gene": range(len(result["true_effects"]["gene_trait_effects"])),
        "trait_effect": result["true_effects"]["gene_trait_effects"],
        "is_causal": [
            i in result["true_effects"]["causal_gene_indices"]
            for i in range(len(result["true_effects"]["gene_trait_effects"]))
        ],
    }).to_csv(output_dir / "true_effects.csv", index=False)
    
    # TWAS results (one row per gene, columns for each model)
    n_genes = len(result["true_effects"]["gene_trait_effects"])
    twas_df = pd.DataFrame({"gene": range(n_genes)})
    for model_name, model_results in result["twas_results"].items():
        twas_df[f"{model_name}_z"] = model_results["z_scores"]
        twas_df[f"{model_name}_p"] = model_results["p_values"]
    twas_df.to_csv(output_dir / "twas_results.csv", index=False)
    
    # Model performance
    perf_data = []
    for model_name, perf in result["model_performance"].items():
        perf_data.append({"model": model_name, **perf})
    pd.DataFrame(perf_data).to_csv(output_dir / "model_performance.csv", index=False)
    
    # Summary
    summary = {
        "power_metrics": result["power_metrics"],
        "model_performance": result["model_performance"],
    }
    with open(output_dir / "summary.json", "w") as f:
        json.dump(summary, f, indent=2)
    
    if verbose:
        print(f"Outputs saved to: {output_dir}")
```

**Step 4: Update scripts/twas/__init__.py**

Update `scripts/twas/__init__.py`:

```python
# scripts/twas/__init__.py
"""
TWAS simulation package.

Provides tools for simulating Transcriptome-Wide Association Studies
for methods development, power analysis, and teaching.
"""

from .simulate import simulate_twas
from .genotype import load_plink, GenotypeData
from .expression import simulate_expression, simulate_multi_gene_expression
from .association import run_twas, compute_twas_z, compute_power_fdr
from .models import get_model, get_available_models

__all__ = [
    "simulate_twas",
    "load_plink",
    "GenotypeData",
    "simulate_expression",
    "simulate_multi_gene_expression",
    "run_twas",
    "compute_twas_z",
    "compute_power_fdr",
    "get_model",
    "get_available_models",
]
```

**Step 5: Run tests to verify they pass**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_simulate.py -v
```

Expected: All 3 tests PASS

**Step 6: Commit**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && git add scripts/twas/ tests/twas/test_simulate.py && git commit -m "feat(twas): add main simulation orchestrator

- Complete TWAS simulation pipeline
- Multi-model support (elastic_net, lasso, gblup, true_effects)
- Power and FDR metrics
- JSON/CSV output files

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Task 8: TWAS Visualizations

**Files:**
- Create: `visualization/twas_plots.py`
- Update: `visualization/__init__.py`
- Create: `tests/twas/test_visualization.py`

**Step 1: Write failing tests**

Create `tests/twas/test_visualization.py`:

```python
# tests/twas/test_visualization.py
"""Tests for TWAS visualization functions."""

import pytest
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt


def test_create_power_curve():
    """Test power curve plotting."""
    from visualization.twas_plots import create_power_curve
    
    results = pd.DataFrame({
        "param_value": [100, 250, 500, 1000],
        "power": [0.2, 0.4, 0.6, 0.8],
        "power_se": [0.05, 0.04, 0.03, 0.02],
    })
    
    fig = create_power_curve(results, vary_param="n_eqtl")
    assert fig is not None
    plt.close(fig)


def test_create_model_comparison():
    """Test model comparison barplot."""
    from visualization.twas_plots import create_model_comparison
    
    results = pd.DataFrame({
        "model": ["elastic_net", "lasso", "gblup"],
        "cv_r2": [0.15, 0.12, 0.18],
        "cv_r2_se": [0.02, 0.02, 0.03],
    })
    
    fig = create_model_comparison(results)
    assert fig is not None
    plt.close(fig)


def test_create_twas_manhattan():
    """Test TWAS Manhattan plot."""
    from visualization.twas_plots import create_twas_manhattan
    
    np.random.seed(42)
    results = pd.DataFrame({
        "gene": [f"GENE{i}" for i in range(100)],
        "chromosome": np.random.choice(range(1, 23), 100),
        "position": np.random.randint(1e6, 1e8, 100),
        "z_score": np.random.randn(100) * 2,
        "p_value": np.random.uniform(0, 1, 100),
    })
    # Make some significant
    results.loc[:5, "p_value"] = np.random.uniform(1e-10, 1e-5, 6)
    
    fig = create_twas_manhattan(results)
    assert fig is not None
    plt.close(fig)


def test_create_qq_plot():
    """Test QQ plot for p-values."""
    from visualization.twas_plots import create_qq_plot
    
    np.random.seed(42)
    p_values = np.random.uniform(0, 1, 1000)
    # Add some significant ones
    p_values[:10] = np.random.uniform(1e-8, 1e-4, 10)
    
    fig = create_qq_plot(p_values)
    assert fig is not None
    plt.close(fig)
```

**Step 2: Run tests to verify they fail**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_visualization.py -v
```

Expected: FAIL with import errors

**Step 3: Implement twas_plots.py**

Create `visualization/twas_plots.py`:

```python
# visualization/twas_plots.py
"""
TWAS visualization functions.

Creates publication-ready figures for:
- Power curves across parameter values
- Model comparison plots
- TWAS Manhattan plots
- QQ plots for p-value calibration
"""

from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns


def create_power_curve(
    results: pd.DataFrame,
    vary_param: str,
    output_path: str | Path | None = None,
    figsize: tuple[float, float] = (8, 6),
    title: str | None = None,
    color: str = "#3498db",
) -> plt.Figure:
    """
    Create a power curve showing power vs parameter value.
    
    Args:
        results: DataFrame with columns: param_value, power, power_se (optional)
        vary_param: Name of the varied parameter (for axis label)
        output_path: Path to save figure
        figsize: Figure size
        title: Plot title
        color: Line color
        
    Returns:
        matplotlib Figure
    """
    results = results.copy()
    results.columns = results.columns.str.lower()
    
    fig, ax = plt.subplots(figsize=figsize)
    
    x = results["param_value"]
    y = results["power"]
    
    # Plot with error bands if SE provided
    if "power_se" in results.columns:
        se = results["power_se"]
        ax.fill_between(x, y - 1.96*se, y + 1.96*se, alpha=0.2, color=color)
    
    ax.plot(x, y, marker="o", color=color, linewidth=2, markersize=8)
    
    ax.set_xlabel(vary_param, fontsize=12)
    ax.set_ylabel("Power", fontsize=12)
    ax.set_ylim(0, 1)
    
    if title:
        ax.set_title(title, fontweight="bold")
    else:
        ax.set_title(f"TWAS Power vs {vary_param}", fontweight="bold")
    
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if output_path:
        fig.savefig(output_path, dpi=300, bbox_inches="tight")
    
    return fig


def create_model_comparison(
    results: pd.DataFrame,
    metric: str = "cv_r2",
    output_path: str | Path | None = None,
    figsize: tuple[float, float] = (8, 6),
    title: str = "Model Comparison",
) -> plt.Figure:
    """
    Create a bar plot comparing model performance.
    
    Args:
        results: DataFrame with columns: model, <metric>, <metric>_se (optional)
        metric: Which metric to plot
        output_path: Path to save figure
        figsize: Figure size
        title: Plot title
        
    Returns:
        matplotlib Figure
    """
    results = results.copy()
    results.columns = results.columns.str.lower()
    
    fig, ax = plt.subplots(figsize=figsize)
    
    x = np.arange(len(results))
    colors = sns.color_palette("husl", len(results))
    
    # Plot bars with error bars if SE available
    se_col = f"{metric}_se"
    if se_col in results.columns:
        ax.bar(x, results[metric], yerr=results[se_col] * 1.96,
               color=colors, capsize=5, edgecolor="white", linewidth=0.5)
    else:
        ax.bar(x, results[metric], color=colors, edgecolor="white", linewidth=0.5)
    
    ax.set_xticks(x)
    ax.set_xticklabels(results["model"], rotation=45, ha="right")
    ax.set_ylabel(metric.replace("_", " ").title())
    ax.set_title(title, fontweight="bold")
    
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    
    plt.tight_layout()
    
    if output_path:
        fig.savefig(output_path, dpi=300, bbox_inches="tight")
    
    return fig


def create_twas_manhattan(
    results: pd.DataFrame,
    output_path: str | Path | None = None,
    figsize: tuple[float, float] = (14, 6),
    title: str = "TWAS Manhattan Plot",
    significance_threshold: float = 5e-8,
    suggestive_threshold: float = 1e-5,
) -> plt.Figure:
    """
    Create a Manhattan plot for TWAS results.
    
    Args:
        results: DataFrame with columns: gene, chromosome, position, p_value
        output_path: Path to save figure
        figsize: Figure size
        title: Plot title
        significance_threshold: Genome-wide significance
        suggestive_threshold: Suggestive significance
        
    Returns:
        matplotlib Figure
    """
    results = results.copy()
    results.columns = results.columns.str.lower()
    
    # Calculate -log10(p)
    results["log_p"] = -np.log10(results["p_value"].clip(1e-300))
    
    # Sort by chromosome and position
    results = results.sort_values(["chromosome", "position"])
    
    # Create cumulative position
    chrom_offsets = {}
    offset = 0
    for chrom in sorted(results["chromosome"].unique()):
        chrom_offsets[chrom] = offset
        offset += results[results["chromosome"] == chrom]["position"].max() + 1e7
    
    results["cumulative_pos"] = results.apply(
        lambda r: r["position"] + chrom_offsets[r["chromosome"]], axis=1
    )
    
    fig, ax = plt.subplots(figsize=figsize)
    
    # Color alternating chromosomes
    colors = ["#2ecc71", "#3498db"]
    for i, chrom in enumerate(sorted(results["chromosome"].unique())):
        chrom_data = results[results["chromosome"] == chrom]
        ax.scatter(
            chrom_data["cumulative_pos"],
            chrom_data["log_p"],
            c=colors[i % 2],
            s=20,
            alpha=0.7,
        )
    
    # Add significance lines
    ax.axhline(-np.log10(significance_threshold), color="red", linestyle="--",
               linewidth=1, label=f"p = {significance_threshold}")
    ax.axhline(-np.log10(suggestive_threshold), color="blue", linestyle=":",
               linewidth=1, label=f"p = {suggestive_threshold}")
    
    # Chromosome labels
    chrom_centers = results.groupby("chromosome")["cumulative_pos"].median()
    ax.set_xticks(chrom_centers.values)
    ax.set_xticklabels(chrom_centers.index.astype(int))
    
    ax.set_xlabel("Chromosome")
    ax.set_ylabel("-log10(p-value)")
    ax.set_title(title, fontweight="bold")
    ax.legend(loc="upper right")
    
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    
    plt.tight_layout()
    
    if output_path:
        fig.savefig(output_path, dpi=300, bbox_inches="tight")
    
    return fig


def create_qq_plot(
    p_values: np.ndarray,
    output_path: str | Path | None = None,
    figsize: tuple[float, float] = (7, 7),
    title: str = "QQ Plot",
) -> plt.Figure:
    """
    Create a QQ plot for p-value calibration.
    
    Args:
        p_values: Array of p-values
        output_path: Path to save figure
        figsize: Figure size
        title: Plot title
        
    Returns:
        matplotlib Figure
    """
    # Remove zeros and clip very small values
    p_values = np.array(p_values)
    p_values = p_values[p_values > 0]
    p_values = np.clip(p_values, 1e-300, 1)
    
    # Sort and compute expected
    observed = -np.log10(np.sort(p_values))
    n = len(p_values)
    expected = -np.log10(np.arange(1, n + 1) / (n + 1))
    
    fig, ax = plt.subplots(figsize=figsize)
    
    # Identity line
    max_val = max(observed.max(), expected.max())
    ax.plot([0, max_val], [0, max_val], "r--", linewidth=1, label="Expected")
    
    # QQ points
    ax.scatter(expected, observed, c="#3498db", s=15, alpha=0.6)
    
    ax.set_xlabel("Expected -log10(p)")
    ax.set_ylabel("Observed -log10(p)")
    ax.set_title(title, fontweight="bold")
    
    # Compute lambda (genomic inflation)
    lambda_gc = np.median(observed) / 0.455
    ax.text(0.05, 0.95, f"Î» = {lambda_gc:.2f}",
            transform=ax.transAxes, fontsize=12,
            verticalalignment="top",
            bbox=dict(boxstyle="round", facecolor="white", alpha=0.8))
    
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    
    plt.tight_layout()
    
    if output_path:
        fig.savefig(output_path, dpi=300, bbox_inches="tight")
    
    return fig
```

**Step 4: Update visualization/__init__.py**

Add to `visualization/__init__.py`:

```python
# Add imports at top
from .twas_plots import (
    create_power_curve,
    create_model_comparison,
    create_twas_manhattan,
    create_qq_plot,
)

# Add to __all__ list
__all__ = [
    # ... existing exports ...
    "create_power_curve",
    "create_model_comparison",
    "create_twas_manhattan",
    "create_qq_plot",
]
```

**Step 5: Run tests to verify they pass**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/test_visualization.py -v
```

Expected: All 4 tests PASS

**Step 6: Commit**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && git add visualization/ tests/twas/test_visualization.py && git commit -m "feat(twas): add visualization functions

- Power curve plots
- Model comparison bar charts
- TWAS Manhattan plots
- QQ plots for p-value calibration

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Task 9: Integration Tests and Documentation

**Files:**
- Create: `tests/twas/test_integration.py`
- Update: `SKILL.md` with TWAS section
- Update: `README.md` roadmap

**Step 1: Create integration tests**

Create `tests/twas/test_integration.py`:

```python
# tests/twas/test_integration.py
"""Integration tests for TWAS simulation pipeline."""

import pytest
import numpy as np
import tempfile
from pathlib import Path


@pytest.fixture
def simulated_genotypes():
    """Generate realistic simulated genotypes."""
    np.random.seed(42)
    n_samples = 1000
    n_genes = 50
    n_snps_per_gene = 100
    
    genotypes = []
    for _ in range(n_genes):
        # Simulate with realistic LD structure (block diagonal)
        g = np.random.randint(0, 3, (n_samples, n_snps_per_gene)).astype(float)
        # Standardize
        g = (g - g.mean(0)) / (g.std(0) + 1e-8)
        genotypes.append(g)
    
    return genotypes


def test_full_simulation_pipeline(simulated_genotypes):
    """Test the complete TWAS simulation pipeline."""
    from scripts.twas import simulate_twas
    
    with tempfile.TemporaryDirectory() as tmpdir:
        result = simulate_twas(
            genotypes_list=simulated_genotypes,
            n_causal_genes=5,
            h2_cis=0.1,
            h2_trait=0.5,
            prop_mediated=0.2,
            n_causal_cis=3,
            models=["elastic_net", "lasso"],
            output_dir=tmpdir,
            seed=42,
            verbose=False,
        )
        
        # Check result structure
        assert "twas_results" in result
        assert "model_performance" in result
        assert "power_metrics" in result
        
        # Check all files created
        assert Path(tmpdir, "simulation_params.json").exists()
        assert Path(tmpdir, "true_effects.csv").exists()
        assert Path(tmpdir, "twas_results.csv").exists()
        assert Path(tmpdir, "model_performance.csv").exists()
        assert Path(tmpdir, "summary.json").exists()
        
        # Check power is reasonable (with known causal genes, should have some power)
        for model in ["elastic_net", "lasso"]:
            assert result["power_metrics"][model]["power"] >= 0
            assert result["power_metrics"][model]["fdr"] <= 1


def test_models_produce_different_results(simulated_genotypes):
    """Test that different models produce different predictions."""
    from scripts.twas import simulate_twas
    
    with tempfile.TemporaryDirectory() as tmpdir:
        result = simulate_twas(
            genotypes_list=simulated_genotypes[:10],  # Smaller for speed
            n_causal_genes=2,
            h2_cis=0.1,
            h2_trait=0.5,
            prop_mediated=0.2,
            models=["elastic_net", "lasso", "gblup"],
            output_dir=tmpdir,
            seed=42,
            verbose=False,
        )
        
        # Models should have different performance
        perf = result["model_performance"]
        r2_values = [perf[m]["mean_cv_r2"] for m in ["elastic_net", "lasso", "gblup"]]
        
        # At least some variation between models
        assert max(r2_values) > min(r2_values) or all(r == 0 for r in r2_values)


def test_visualization_integration():
    """Test that visualizations work with simulation output."""
    from scripts.twas import simulate_twas
    from visualization.twas_plots import create_model_comparison, create_qq_plot
    import pandas as pd
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    
    np.random.seed(42)
    n_samples, n_genes, n_snps = 200, 10, 30
    genotypes = [
        np.random.randn(n_samples, n_snps)
        for _ in range(n_genes)
    ]
    
    with tempfile.TemporaryDirectory() as tmpdir:
        result = simulate_twas(
            genotypes_list=genotypes,
            n_causal_genes=2,
            h2_cis=0.1,
            h2_trait=0.5,
            prop_mediated=0.1,
            models=["elastic_net"],
            output_dir=tmpdir,
            seed=42,
            verbose=False,
        )
        
        # Create model comparison from output
        perf_df = pd.read_csv(Path(tmpdir) / "model_performance.csv")
        perf_df.columns = ["model", "cv_r2", "cv_corr", "n_nonzero"]
        fig1 = create_model_comparison(perf_df, metric="cv_r2")
        assert fig1 is not None
        plt.close(fig1)
        
        # Create QQ plot from p-values
        twas_df = pd.read_csv(Path(tmpdir) / "twas_results.csv")
        p_values = twas_df["elastic_net_p"].values
        fig2 = create_qq_plot(p_values)
        assert fig2 is not None
        plt.close(fig2)


def test_reproducibility_with_seed(simulated_genotypes):
    """Test that results are reproducible with same seed."""
    from scripts.twas import simulate_twas
    
    with tempfile.TemporaryDirectory() as tmpdir1, tempfile.TemporaryDirectory() as tmpdir2:
        result1 = simulate_twas(
            genotypes_list=simulated_genotypes[:5],
            n_causal_genes=2,
            h2_cis=0.1,
            h2_trait=0.5,
            prop_mediated=0.1,
            models=["elastic_net"],
            output_dir=tmpdir1,
            seed=42,
            verbose=False,
        )
        
        result2 = simulate_twas(
            genotypes_list=simulated_genotypes[:5],
            n_causal_genes=2,
            h2_cis=0.1,
            h2_trait=0.5,
            prop_mediated=0.1,
            models=["elastic_net"],
            output_dir=tmpdir2,
            seed=42,
            verbose=False,
        )
        
        # Results should be identical
        np.testing.assert_allclose(
            result1["twas_results"]["elastic_net"]["z_scores"],
            result2["twas_results"]["elastic_net"]["z_scores"],
            rtol=1e-5,
        )
```

**Step 2: Run all tests**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/twas/ -v
```

Expected: All tests PASS

**Step 3: Update SKILL.md with TWAS section**

Add the TWAS section to SKILL.md (append after LDSC section):

```markdown
### TWAS Simulator

Simulate Transcriptome-Wide Association Studies for methods development, power analysis, and teaching.

**Capabilities:**
- Simulate gene expression with configurable cis-heritability
- Multiple expression prediction models (Elastic Net, LASSO, GBLUP, oracle)
- Full TWAS pipeline: expression â weights â association
- Power and FDR calculation
- Single run, power analysis, and batch modes

**API Functions:**
- `simulate_twas(genotypes, n_causal_genes, ...)` - Run complete simulation
- `simulate_expression(genotypes, h2_cis, n_causal)` - Simulate expression only
- `run_twas(pred_expression, phenotype)` - TWAS association test
- `get_model(name)` - Get expression prediction model

**Example Usage:**

```
# Basic simulation
"Simulate a TWAS with 100 genes, 10 causal, h2_cis=0.1"

# Power analysis
"Run TWAS power analysis varying eQTL sample size from 100 to 1000"

# Model comparison
"Compare Elastic Net vs LASSO for TWAS prediction"
```

**Key Parameters:**

| Parameter | Default | Description |
|-----------|---------|-------------|
| `h2_cis` | 0.1 | Cis-heritability of expression |
| `h2_trait` | 0.5 | Total trait heritability |
| `prop_mediated` | 0.1 | Fraction of hÂ² mediated through expression |
| `n_causal_cis` | 1 | Causal cis-eQTLs per gene |
| `n_causal_genes` | 10 | Genes with trait effects |
```

**Step 4: Update README.md roadmap**

Edit README.md to check the TWAS simulator box:

```markdown
## Roadmap

- [x] SuSiE fine-mapping
- [x] LDSC (LD Score Regression) - heritability, genetic correlation, s-LDSC
- [ ] TWAS (Transcriptome-Wide Association Studies)
- [x] TWAS simulator
```

**Step 5: Commit documentation updates**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && git add SKILL.md README.md tests/twas/test_integration.py && git commit -m "docs: add TWAS simulator documentation and integration tests

- SKILL.md: Add TWAS simulator section with API reference
- README.md: Check TWAS simulator in roadmap
- tests: Add comprehensive integration tests

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

**Step 6: Run full test suite**

```bash
cd /Users/camellia/conductor/workspaces/statgen_skills/pattaya && python -m pytest tests/ -v --tb=short
```

Expected: All tests PASS

---

## Summary

This plan implements the TWAS simulator in 9 tasks:

1. **Genotype Manager** - PLINK loading, cis-region subsetting
2. **Model Base Class** - Abstract interface and registry
3. **ElasticNet & LASSO** - Sparse penalized regression
4. **GBLUP & TrueEffects** - Dense and oracle models
5. **Expression Simulation** - Genetic architecture simulation
6. **Association Testing** - TWAS Z-scores, power/FDR
7. **Main Orchestrator** - Complete simulation pipeline
8. **Visualizations** - Power curves, Manhattan, QQ plots
9. **Integration & Docs** - Full tests and documentation

Each task follows TDD: write failing tests â implement â verify â commit.
